{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Evaluation\n",
    "Evaluate and compare different classication models to find the best performing algorithm to predict the target feature of the data set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the framework and generate the models for comparison\n",
    "\n",
    "For the general steps, the methods of the ML_Framework.py will be used, but for sophisticated predictions, some other libraries are necessary as well. The most crucial point is the data splitting for training and testing, since the percentage of drafted players is relatively low (around 1%). \n",
    "\n",
    "So to prepare the model for more accurate performance, it is necessary to somehow create similarly distributed folds. For this purpose, I will use Stratified K-Fold Cross Validation. This method splits the data into a training and a test set and repeats the splitting for a specified number of times (parameter: number of splits). Each split is followed by fitting the model to the training data, and performing predictions on the test set. Finally, the evaluation of the prediction takes place to analyze the performance of each and every iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ML_Framework\n",
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define different classification models for comparison\n",
    "\n",
    "The ML_Framework.py file contains a Model class. When the Model class is called, a Model instance is going to be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = ML_Framework.Model() # random model\n",
    "logreg_model = ML_Framework.Model(user_defined_model='lr',logreg_params=['l2','lbfgs']) # logistic regression model with 'l2' penalty and 'lbfgs' solver settings\n",
    "dtree_model = ML_Framework.Model(user_defined_model='dt', dectree_params=['best',10,'gini']) # decision tree model with 'best' splitter, maximum depth = 10 and 'gini' criterion settings\n",
    "randfor_model = ML_Framework.Model(user_defined_model='rf',randfor_params=[20,5,'gini']) # random forest model with number of estimator trees = 20, maximum depth = 5 and 'gini' criterion settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transform the input data for all models using the framework's transform() method\n",
    "The transform method applies all data cleansing, transforming and handling of missing values steps from the EDA.ipynb file's 2nd and 3rd sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model.transform()\n",
    "logreg_model.transform()\n",
    "dtree_model.transform()\n",
    "randfor_model.transform()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model evaluation using Stratified K-Fold Cross Validation\n",
    "After cleaning the data and separating the predictors from the target feature, the next steps would be the model fitting, prediction and evaluation in the very same order as they were listed. However, for more accurate results, these steps will be applied repeatedly, many times in a loop using the stratified k-fold cross validation. The main point of stratified K-fold is that this validator preserves the percentage of samples for each class, which gives a more realistic training and test split for the model.\n",
    "\n",
    "Each of the following subsections focuses on one of the four different models created in the previous step. At the end of each subsection the output of the certain cell will be the evaluation of the actual model performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Random model evaluation\n",
    "\n",
    "Apply different number of splits, then fit, predict and evaluate the model's performance on those splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of splits: 10\n",
      "Maximum Precision: 3.3333333333333335 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 0.8306010928961749 %\n",
      "Standard Deviation: 0.011763944218474078\n",
      "\n",
      "Number of splits: 50\n",
      "Maximum Precision: 8.333333333333332 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 0.6666666666666666 %\n",
      "Standard Deviation: 0.022837292968155808\n",
      "\n",
      "Number of splits: 100\n",
      "Maximum Precision: 16.666666666666664 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 0.5 %\n",
      "Standard Deviation: 0.028574434666294213\n"
     ]
    }
   ],
   "source": [
    "# for the random model it is necessary to ignore cases where the model was unable to predict the target feature\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for n in [10,50,100]:\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)\n",
    "    prec_skf = []\n",
    "\n",
    "    for train_index, test_index in skf.split(random_model.X_scaled, random_model.y):\n",
    "        # split X and y\n",
    "        random_model.X_train, random_model.X_test = random_model.X_scaled[train_index], random_model.X_scaled[test_index]\n",
    "        random_model.y_train, random_model.y_test = random_model.y[train_index], random_model.y[test_index]\n",
    "        \n",
    "        # evaluate the model\n",
    "        cm, cr = random_model.evaluate(random_model.random_model())\n",
    "\n",
    "        prec_skf.append(cr.iloc[1,1]) # precision for drafted_flag = 1 predictions\n",
    "\n",
    "    # print out evaluation results\n",
    "    print('\\nNumber of splits: {}'.format(n))\n",
    "#    print('List of possible accuracy:', accuracy_skf)\n",
    "    print('Maximum Precision:',\n",
    "        max(prec_skf)*100, '%')\n",
    "    print('Minimum Precision:',\n",
    "        min(prec_skf)*100, '%')\n",
    "    print('Overall Precision:',\n",
    "        mean(prec_skf)*100, '%')\n",
    "    print('Standard Deviation:', stdev(prec_skf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is visible, that the random model has a really bad performance predicting the players who are going to be drafted. However, the precision of the prediction of drafted players gets better when the number of splits is higher, but after 100 splits, the maximum precision score of predicting drafted players is still around 33%, which is a pretty low value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Logistic Regression model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of splits: 10\n",
      "Maximum Precision: 40.0 %\n",
      "Minimum Precision: 19.672131147540984 %\n",
      "Overall Precision: 28.42896174863388 %\n",
      "Standard Deviation: 0.06767814040748778\n",
      "\n",
      "Number of splits: 50\n",
      "Maximum Precision: 58.333333333333336 %\n",
      "Minimum Precision: 8.333333333333332 %\n",
      "Overall Precision: 28.423076923076923 %\n",
      "Standard Deviation: 0.13799980427797415\n",
      "\n",
      "Number of splits: 100\n",
      "Maximum Precision: 83.33333333333334 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 28.547619047619044 %\n",
      "Standard Deviation: 0.18739985071305545\n"
     ]
    }
   ],
   "source": [
    "for n in [10,50,100]:\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)\n",
    "    prec_skf = []\n",
    "\n",
    "    for train_index, test_index in skf.split(logreg_model.X_scaled, logreg_model.y):\n",
    "        # split X and y\n",
    "        logreg_model.X_train, logreg_model.X_test = logreg_model.X_scaled[train_index], logreg_model.X_scaled[test_index]\n",
    "        logreg_model.y_train, logreg_model.y_test = logreg_model.y[train_index], logreg_model.y[test_index]\n",
    "        \n",
    "        # fit the model\n",
    "        logreg_model.fit()\n",
    "\n",
    "        # predict target feature values and evaluate the model\n",
    "        cm, cr = logreg_model.evaluate(logreg_model.predict())\n",
    "\n",
    "        prec_skf.append(cr.iloc[1,1]) # precision for drafted_flag = 1 predictions\n",
    "\n",
    "    # print out evaluation results\n",
    "    print('\\nNumber of splits: {}'.format(n))\n",
    "#    print('List of possible precision:', prec_skf)\n",
    "    print('Maximum Precision:',\n",
    "        max(prec_skf)*100, '%')\n",
    "    print('Minimum Precision:',\n",
    "        min(prec_skf)*100, '%')\n",
    "    print('Overall Precision:',\n",
    "        mean(prec_skf)*100, '%')\n",
    "    print('Standard Deviation:', stdev(prec_skf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model's performance reaches 83% after 100 splits, which means it is able to predict about 4 out of 5 drafted players correctly. The LogReg beats the random algorithm, and the it provides a good predictive model to find those players who are going to be drafted.\n",
    "\n",
    "However, the overall precision is under 30% with almost 20% standard deviation (in this context it means the standard deviation of the percentage), which means the high performance is not a usual phenomenom. Unfortunately, it is not a stable model for this prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Decision Tree model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of splits: 10\n",
      "Maximum Precision: 43.333333333333336 %\n",
      "Minimum Precision: 24.59016393442623 %\n",
      "Overall Precision: 33.404371584699454 %\n",
      "Standard Deviation: 0.05018755404797663\n",
      "\n",
      "Number of splits: 50\n",
      "Maximum Precision: 58.333333333333336 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 35.205128205128204 %\n",
      "Standard Deviation: 0.14770491689880583\n",
      "\n",
      "Number of splits: 100\n",
      "Maximum Precision: 83.33333333333334 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 33.88095238095238 %\n",
      "Standard Deviation: 0.20117428802302334\n"
     ]
    }
   ],
   "source": [
    "for n in [10,50,100]:\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)\n",
    "    prec_skf = []\n",
    "\n",
    "    for train_index, test_index in skf.split(dtree_model.X_scaled, dtree_model.y):\n",
    "        # split X and y\n",
    "        dtree_model.X_train, dtree_model.X_test = dtree_model.X_scaled[train_index], dtree_model.X_scaled[test_index]\n",
    "        dtree_model.y_train, dtree_model.y_test = dtree_model.y[train_index], dtree_model.y[test_index]\n",
    "        \n",
    "        # fit the model\n",
    "        dtree_model.fit()\n",
    "\n",
    "        # predict target feature values and evaluate the model\n",
    "        cm, cr = dtree_model.evaluate(dtree_model.predict())\n",
    "\n",
    "        prec_skf.append(cr.iloc[1,1]) # precision for drafted_flag = 1 predictions\n",
    "\n",
    "    # print out evaluation results\n",
    "    print('\\nNumber of splits: {}'.format(n))\n",
    "#    print('List of possible precision:', prec_skf)\n",
    "    print('Maximum Precision:',\n",
    "        max(prec_skf)*100, '%')\n",
    "    print('Minimum Precision:',\n",
    "        min(prec_skf)*100, '%')\n",
    "    print('Overall Precision:',\n",
    "        mean(prec_skf)*100, '%')\n",
    "    print('Standard Deviation:', stdev(prec_skf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree algorithm performs slightly better than the previous logistic regression, but it faces the same problem: low overall precision value and high standard deviation, which means this model works very efficiently in case of a specific data split, but it does not perform well in general, just like the logistic regression model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Random Forest model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of splits: 10\n",
      "Maximum Precision: 20.0 %\n",
      "Minimum Precision: 9.836065573770492 %\n",
      "Overall Precision: 13.633879781420767 %\n",
      "Standard Deviation: 0.039472233356886086\n",
      "\n",
      "Number of splits: 50\n",
      "Maximum Precision: 41.66666666666667 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 13.448717948717947 %\n",
      "Standard Deviation: 0.0961973562816552\n",
      "\n",
      "Number of splits: 100\n",
      "Maximum Precision: 50.0 %\n",
      "Minimum Precision: 0.0 %\n",
      "Overall Precision: 14.309523809523808 %\n",
      "Standard Deviation: 0.14215375174880387\n"
     ]
    }
   ],
   "source": [
    "for n in [10,50,100]:\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)\n",
    "    prec_skf = []\n",
    "\n",
    "    for train_index, test_index in skf.split(randfor_model.X_scaled, randfor_model.y):\n",
    "        # split X and y\n",
    "        randfor_model.X_train, randfor_model.X_test = randfor_model.X_scaled[train_index], randfor_model.X_scaled[test_index]\n",
    "        randfor_model.y_train, randfor_model.y_test = randfor_model.y[train_index], randfor_model.y[test_index]\n",
    "        \n",
    "        # fit the model\n",
    "        randfor_model.fit()\n",
    "\n",
    "        # predict target feature values and evaluate the model\n",
    "        cm, cr = randfor_model.evaluate(randfor_model.predict())\n",
    "\n",
    "        prec_skf.append(cr.iloc[1,1]) # precision for drafted_flag = 1 predictions\n",
    "\n",
    "    # print out evaluation results\n",
    "    print('\\nNumber of splits: {}'.format(n))\n",
    "#    print('List of possible precision:', prec_skf)\n",
    "    print('Maximum Precision:',\n",
    "        max(prec_skf)*100, '%')\n",
    "    print('Minimum Precision:',\n",
    "        min(prec_skf)*100, '%')\n",
    "    print('Overall Precision:',\n",
    "        mean(prec_skf)*100, '%')\n",
    "    print('Standard Deviation:', stdev(prec_skf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performed worse than all previously built models (except the random model), with the maximum precision value of 50% and only 14% overall precision for the drafted players. It also had a quite large standard deviation of 14%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion\n",
    "\n",
    "The random model had a really low precision score, so it was an easy task for the models to beat its score. Finally, all constructed machine learning algorithms were able to surpass the random model's performance. \n",
    "However, amongst the defined and built models, the decision tree classifier had the highest maximum precision value, but the logistic regression reached almost the same value for the maximum precision.\n",
    "\n",
    "From another point of view, neither model was able to produce a good overall precision score, which means that during the iteration of the cross validation, there were a few good splits (or just the one with the maximum precision), which can be used for training an accurate model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Further steps\n",
    "\n",
    "The machine learning task for this project was to find those college basketball players who are most likely going to be selected on the NBA draft. \n",
    "The goal was to make a good predictive model, which can provide high precision results. This was a binary task, since the target feature has only two outcomes: a player can be selected, or not selected on the draft. \n",
    "However, based on the input data, there are many other features that could be predicted, such as which NBA team will select a certain player on the draft, or in which round will that player be selected (first or second)?\n",
    "\n",
    "On the other hand, the algorithms introduced above have hyperparameters. Those hyperparameters were not tuned during the model building steps, which means there might be better performing versions and settings of these models. \n",
    "Also, it is important to mention that the cross validation process had its own limitations, such as computer memory. Therefore, a more powerful machine might be able to run the model on 1000 different data splits which might lead to better precision scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac7d29c965e45fe5a19c676ea45bb965084d69bd807afb6434490090b4c39e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
